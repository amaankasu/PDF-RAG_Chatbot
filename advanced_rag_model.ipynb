{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF RAG Chatbot Advanced Model\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) approach to query PDFs. It extracts text (both structured and raw), splits the text into meaningful chunks, creates vector embeddings using a Sentence Transformer, builds a FAISS index for fast search, applies BM25 filtering, and finally generates answers using OpenAI's ChatCompletion API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85 (from -r advanced_rag_requirements.txt (line 53))\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.1/12.8 MB 299.4 kB/s eta 0:00:43\n",
      "     --------------------------------------- 0.1/12.8 MB 438.1 kB/s eta 0:00:30\n",
      "     --------------------------------------- 0.1/12.8 MB 438.1 kB/s eta 0:00:30\n",
      "     --------------------------------------- 0.1/12.8 MB 438.1 kB/s eta 0:00:30\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.3/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.3/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.3/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.3/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 2.0/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 2.7/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 3.1/12.8 MB 2.1 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.1/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.5/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.1/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.0/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.5/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.0/12.8 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.3/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.5/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.8/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 5.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: aiofiles==24.1.0 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 1)) (24.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.6 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: aiohttp==3.10.11 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 3)) (3.10.11)\n",
      "Requirement already satisfied: aiohttp-retry==2.8.3 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 4)) (2.8.3)\n",
      "Requirement already satisfied: aioice==0.9.0 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: aiortc==1.9.0 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: Flask in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: flask-cors in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 8)) (5.0.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 9)) (0.110.3)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 10)) (1.3.2)\n",
      "Requirement already satisfied: aiosqlite==0.21.0 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: anthropic==0.34.2 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 13)) (0.34.2)\n",
      "Requirement already satisfied: anyio==4.8.0 in c:\\users\\amaan\\desktop\\rag chatbot\\advanced_rag_venv\\lib\\site-packages (from -r advanced_rag_requirements.txt (line 14)) (4.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement react-icons (from versions: none)\n",
      "ERROR: No matching distribution found for react-icons\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages and download the spaCy model.\n",
    "!pip install -r advanced_rag_requirements.txt\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Environment Setup\n",
    "This cell imports all necessary libraries, configures logging, and loads environment variables (like the OpenAI API key). It also initializes the spaCy NLP model and the Sentence Transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import fitz  # PyMuPDF for raw PDF text extraction\n",
    "import spacy  # For NLP tasks (tokenization, sentence segmentation)\n",
    "import numpy as np\n",
    "import faiss  # For fast vector search\n",
    "from sentence_transformers import SentenceTransformer  # To convert text into embeddings\n",
    "import openai  # For generating answers using OpenAI's API\n",
    "from dotenv import load_dotenv  # To load environment variables\n",
    "from unstructured.partition.pdf import partition_pdf  # For structured PDF extraction\n",
    "from rank_bm25 import BM25Okapi  # For keyword-based ranking (BM25)\n",
    "\n",
    "# Configure logging to record performance and errors\n",
    "logging.basicConfig(\n",
    "    filename=\"benchmark.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "print(\"Loaded API Key:\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load the spaCy model and set max_length for long documents\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 2000000\n",
    "\n",
    "# Load the Sentence Transformer model for creating embeddings\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create an in-memory dictionary (if needed later)\n",
    "documents = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Text Extraction Functions\n",
    "This cell defines functions to extract text from PDFs. The function `extract_structured_content` uses Unstructured to partition the PDF into structured elements, while `extract_text_from_pdf` is a fallback that extracts raw text using PyMuPDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Fallback extraction using PyMuPDF.\n",
    "    Opens the PDF and extracts text from all pages.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_structured_content(file_path: str):\n",
    "    \"\"\"\n",
    "    Uses Unstructured to partition a PDF into structured elements.\n",
    "    Returns a list of dictionaries with keys \"type\" and \"text\".\n",
    "    \"\"\"\n",
    "    elements = partition_pdf(filename=file_path)\n",
    "    structured_data = []\n",
    "    for element in elements:\n",
    "        structured_data.append({\n",
    "            \"type\": element.type,  # e.g., \"Title\", \"Heading\", \"Text\"\n",
    "            \"text\": element.text.strip(),\n",
    "        })\n",
    "    return structured_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Tagging Function\n",
    "The following function groups extracted elements into technical sections (like Abstract, Introduction, etc.) using regex. This helps organize the document content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sections_technical(structured_elements):\n",
    "    \"\"\"\n",
    "    Groups extracted elements into sections for technical papers.\n",
    "    Uses regex to capture common section headers.\n",
    "    \"\"\"\n",
    "    section_pattern = re.compile(\n",
    "        r\"(Abstract|Introduction|Related Work|Background|Methodology|Approach|Experiments|Results|Discussion|Conclusion|Encoding|CLIP|Text Encoder|Embedding)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    tagged_sections = {}\n",
    "    current_section = None\n",
    "\n",
    "    for element in structured_elements:\n",
    "        element_type = element.get(\"type\", \"\").lower()\n",
    "        text = element.get(\"text\", \"\")\n",
    "        if element_type in [\"heading\", \"title\"] or section_pattern.search(text):\n",
    "            match = section_pattern.search(text)\n",
    "            new_section = match.group(0).strip() if match else text.strip()\n",
    "            current_section = new_section\n",
    "            if current_section not in tagged_sections:\n",
    "                tagged_sections[current_section] = []\n",
    "        elif current_section:\n",
    "            tagged_sections[current_section].append(text)\n",
    "        else:\n",
    "            tagged_sections.setdefault(\"Body\", []).append(text)\n",
    "    \n",
    "    for section in tagged_sections:\n",
    "        tagged_sections[section] = \"\\n\".join(tagged_sections[section]).strip()\n",
    "    return tagged_sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Text Extraction Function\n",
    "This function attempts structured extraction and section tagging first; if that fails, it falls back to raw extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_extract_text(file_path: str) -> (str, dict):\n",
    "    \"\"\"\n",
    "    Extracts text via structured partitioning and tags technical sections.\n",
    "    Falls back to basic extraction if necessary.\n",
    "    Returns a tuple (combined_text, tagged_sections).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        structured_elements = extract_structured_content(file_path)\n",
    "        tagged_sections = tag_sections_technical(structured_elements)\n",
    "        combined_text = \"\\n\\n\".join([f\"{section}: {content}\" for section, content in tagged_sections.items()])\n",
    "        if combined_text.strip():\n",
    "            return combined_text, tagged_sections\n",
    "        else:\n",
    "            raise Exception(\"No structured content extracted.\")\n",
    "    except Exception as e:\n",
    "        logging.info(\"Structured extraction failed; using fallback extraction. Error: \" + str(e))\n",
    "        fallback_text = extract_text_from_pdf(file_path)\n",
    "        return fallback_text, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Chunking Function\n",
    "This function splits the extracted text into semantically coherent chunks using sentence segmentation and linguistic cues (transition words). It dynamically determines the chunk size based on the average token count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_chunk_text_dynamic(text: str, min_threshold: int = None, factor: float = 1.5, transition_words=None) -> list:\n",
    "    \"\"\"\n",
    "    Splits text into semantically coherent chunks using a dynamic token threshold.\n",
    "    Uses linguistic cues (transition words) to determine natural boundaries.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
    "    \n",
    "    # Use spaCy for sentence segmentation\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "    \n",
    "    token_counts = [len(sent.split()) for sent in sentences]\n",
    "    if not token_counts:\n",
    "        return [text]\n",
    "    avg_tokens = sum(token_counts) / len(token_counts)\n",
    "    \n",
    "    if min_threshold is None:\n",
    "        min_threshold = int(avg_tokens)\n",
    "    threshold = int(max(min_threshold, avg_tokens * factor))\n",
    "    \n",
    "    if transition_words is None:\n",
    "        transition_words = [\"however\", \"moreover\", \"furthermore\", \"in conclusion\", \"finally\", \"additionally\"]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_token_count = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        sent_tokens = len(sent.split())\n",
    "        if current_chunk:\n",
    "            sent_lower = sent.lower()\n",
    "            starts_with_transition = any(sent_lower.startswith(word) for word in transition_words)\n",
    "        else:\n",
    "            starts_with_transition = False\n",
    "        \n",
    "        if (current_token_count + sent_tokens > threshold) or (starts_with_transition and current_token_count > int(threshold * 0.7)):\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sent\n",
    "            current_token_count = sent_tokens\n",
    "        else:\n",
    "            current_chunk += \" \" + sent\n",
    "            current_token_count += sent_tokens\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and Indexing Functions\n",
    "These functions:\n",
    "- Compute embeddings for each chunk.\n",
    "- Build a FAISS HNSW index for fast vector search.\n",
    "- Search the index for candidate chunks based on a query.\n",
    "- Optionally filter results using BM25.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(chunks: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes embeddings for each text chunk using the Sentence Transformer.\n",
    "    \"\"\"\n",
    "    embeddings = embed_model.encode(chunks, convert_to_numpy=True)\n",
    "    return embeddings.astype(\"float32\")\n",
    "\n",
    "def build_hnsw_index(embeddings: np.ndarray, M: int = 32, efConstruction: int = 40):\n",
    "    \"\"\"\n",
    "    Builds a FAISS HNSW index from the computed embeddings.\n",
    "    \"\"\"\n",
    "    d = embeddings.shape[1]\n",
    "    index = faiss.IndexHNSWFlat(d, M)\n",
    "    index.hnsw.efConstruction = efConstruction\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def search_index(query: str, index, chunks: list, k: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Uses FAISS vector search to retrieve the top-k candidate chunks.\n",
    "    Logs the search duration.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    query_embedding = embed_model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = [chunks[i] for i in indices[0] if i < len(chunks)]\n",
    "    search_duration = time.time() - start_time\n",
    "    logging.info(f\"HNSW Search Time: {search_duration:.4f} seconds\")\n",
    "    return results\n",
    "\n",
    "def bm25_filter(query, candidate_chunks, threshold=1.0):\n",
    "    \"\"\"\n",
    "    Filters candidate chunks using BM25.\n",
    "    Returns the top candidate if its score meets the threshold.\n",
    "    \"\"\"\n",
    "    if not candidate_chunks:\n",
    "        print(\"BM25 received an empty candidate chunk list.\")\n",
    "        return []\n",
    "    \n",
    "    tokenized_corpus = [doc.lower().split() for doc in candidate_chunks if doc.strip()]\n",
    "    if not tokenized_corpus:\n",
    "        print(\"BM25 corpus is empty after processing. Returning no results.\")\n",
    "        return []\n",
    "    \n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    tokenized_query = query.lower().split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    best_idx = np.argmax(scores)\n",
    "    if scores[best_idx] >= threshold:\n",
    "        return [candidate_chunks[best_idx]]\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Generation Function\n",
    "This function creates a prompt by combining the retrieved context with the user's query, then uses the OpenAI ChatCompletion API to generate an answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query: str, context: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an answer using OpenAI's ChatCompletion API.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are given the following context extracted from a legal document:\n",
    "    \n",
    "{context}\n",
    "\n",
    "Based on the above context, answer the following question:\n",
    "{query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o-mini\",  # or \"gpt-3.5-turbo\" as appropriate\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        answer = f\"Error generating answer: {e}\"\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Execution\n",
    "The following cells demonstrate processing a sample PDF:\n",
    "1. Extract text and tag sections.\n",
    "2. Chunk the text adaptively.\n",
    "3. Compute embeddings and build a FAISS index.\n",
    "4. Retrieve candidate chunks for a sample query.\n",
    "5. Optionally filter using BM25.\n",
    "6. Generate and display the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged Sections:\n",
      "Total Chunks: 33\n",
      "Sample Chunk (first 300 characters):\n",
      "1 POWER OF ATTORNEY TO ALL TO WHOM THESE PRESENTS SHALL COME I, MR. ISMAIL MOHIDEEN ALI HASHIM MOHAMMED ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving candidate chunks for query: 'What is the permanent address of the property?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW Search Time: 0.0237 seconds\n",
      "\n",
      "Candidate Chunks and Similarity Scores:\n",
      "Chunk 1:\n",
      "Similarity Score: 0.978529691696167\n",
      "Text (first 300 characters): To receive and recover the vacant possession of the premises in said property at the time the respective tenant, lessee, licensee, occupants thereof surrenders the same relinquishing all his/her/their rights, title claims and interest thereto and then either to retain the vacant possession of the pr...\n",
      "\n",
      "Chunk 2:\n",
      "Similarity Score: 0.9805436134338379\n",
      "Text (first 300 characters): as the case may be in respect of the said property, as my said attorney think fit and proper. 7....\n",
      "\n",
      "Chunk 3:\n",
      "Similarity Score: 1.0202440023422241\n",
      "Text (first 300 characters): To answer any communications, letters, documents, notices etc. which relate to the said property and carry on and conduct all the correspondence that may be necessary and discharge all lawful claims obligations and liabilities arising from any contract. Statutory laws, rules and regulations etc....\n",
      "\n",
      "Chunk 4:\n",
      "Similarity Score: 1.0413366556167603\n",
      "Text (first 300 characters): 14. To enter into an agreement with respect to admit and Execution of Sale Deed of the below mentioned property under my ownership before the Registrar and Sub- Registrar of Assurances in Mumbai and in Sub-urban Mumbai. 7 15....\n",
      "\n",
      "No BM25 candidates passed the threshold. Using all candidate chunks.\n",
      "\n",
      "Final Context for LLM Prompt:\n",
      "To receive and recover the vacant possession of the premises in said property at the time the respective tenant, lessee, licensee, occupants thereof surrenders the same relinquishing all his/her/their rights, title claims and interest thereto and then either to retain the vacant possession of the premises received and recovered as 6 aforesaid or to give wholly or any part or parts thereof on tenancy or on any other terms, conditions or basis of whatsoever nature to one or more person or persons as my Attorney may think fit. 11.\n",
      "\n",
      "as the case may be in respect of the said property, as my said attorney think fit and proper. 7.\n",
      "\n",
      "To answer any communications, letters, documents, notices etc. which relate to the said property and carry on and conduct all the correspondence that may be necessary and discharge all lawful claims obligations and liabilities arising from any contract. Statutory laws, rules and regulations etc.\n",
      "\n",
      "14. To enter into an agreement with respect to admit and Execution of Sale Deed of the below mentioned property under my ownership before the Registrar and Sub- Registrar of Assurances in Mumbai and in Sub-urban Mumbai. 7 15. \n",
      "\n",
      "Generated Answer:\n",
      "The context provided does not specify the permanent address of the property. It only mentions that the property is located in Mumbai and Sub-urban Mumbai. For the exact address, additional information would be needed that is not present in the provided text.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to a sample PDF (adjust as needed)\n",
    "test_pdf_path = r\"C:\\Users\\amaan\\Desktop\\RAG Chatbot\\data\\poa.pdf\"\n",
    "\n",
    "# Step 1: Extract and tag text from the PDF.\n",
    "extracted_text, tagged_sections = robust_extract_text(test_pdf_path)\n",
    "print(\"Tagged Sections:\")\n",
    "for section, content in tagged_sections.items():\n",
    "    print(f\"--- {section} ---\\n{content[:300]}...\\n\")  # Print first 300 characters for brevity\n",
    "\n",
    "# Step 2: Adaptive Chunking.\n",
    "chunks = adaptive_chunk_text_dynamic(extracted_text)\n",
    "print(f\"Total Chunks: {len(chunks)}\")\n",
    "print(\"Sample Chunk (first 300 characters):\")\n",
    "print(chunks[0][:300], \"...\\n\")\n",
    "\n",
    "# Step 3: Generate embeddings and build the FAISS index.\n",
    "embeddings = get_embeddings(chunks)\n",
    "index = build_hnsw_index(embeddings)\n",
    "\n",
    "# Step 4: Retrieve candidate chunks with similarity scores.\n",
    "query = \"What is the permanent address of the property?\"\n",
    "print(f\"Retrieving candidate chunks for query: '{query}'\")\n",
    "start_time = time.time()\n",
    "query_embedding = embed_model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "distances, indices = index.search(query_embedding, k=4)\n",
    "search_duration = time.time() - start_time\n",
    "print(f\"HNSW Search Time: {search_duration:.4f} seconds\\n\")\n",
    "\n",
    "candidate_chunks = []\n",
    "print(\"Candidate Chunks and Similarity Scores:\")\n",
    "for i, (idx, score) in enumerate(zip(indices[0], distances[0])):\n",
    "    if idx < len(chunks):\n",
    "         candidate_chunks.append(chunks[idx])\n",
    "         print(f\"Chunk {i+1}:\")\n",
    "         print(f\"Similarity Score: {score}\")\n",
    "         print(f\"Text (first 300 characters): {chunks[idx][:300]}...\\n\")\n",
    "\n",
    "# Step 5: Optionally filter candidate chunks using BM25.\n",
    "filtered_chunks = bm25_filter(query, candidate_chunks, threshold=1.0)\n",
    "if filtered_chunks:\n",
    "    final_context = filtered_chunks[0]  # Use the top BM25 candidate.\n",
    "    print(\"BM25 Filtered Candidate Found.\\n\")\n",
    "else:\n",
    "    final_context = \"\\n\\n\".join(candidate_chunks)\n",
    "    print(\"No BM25 candidates passed the threshold. Using all candidate chunks.\\n\")\n",
    "\n",
    "print(\"Final Context for LLM Prompt:\")\n",
    "print(final_context, \"\\n\")\n",
    "\n",
    "# Step 6: Generate an answer using the final context.\n",
    "answer = generate_answer(query, final_context)\n",
    "print(\"Generated Answer:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
